# 系统分析

## 相关概念

**系统分析：对主要因素和次要因素的分析，以及若要达到效果A，对哪些因素需要强化、哪些因素需要抑制而进行的分析称为系统分析。**

## 主流系统分析的分类

#### 1.  回归分析

##### 1.0 数据的分类

横截面数据：同一时间的数据

时间序列数据：不同时间同一对象的数据

面板数据：不同时间不同对象的数据

##### 1.1 线性回归

模型：OLS，GLS					Y的特点：连续数值型变量；		例子：GDP，产量，收入

***一元线性回归***


假设$x$是自变量，$y$是因变量，且满足如下线性关系：

$$
y_i = \beta_0+\beta_1 x_i+\mu_i
$$

$\beta_0$和$\beta_1$为回归系数，$u_i$为无法观测的且满足一定条件的扰动项

令观测值

$$
\hat{y_i} = \hat{\beta_0}+\hat{\beta_1}x_i
$$

其中 
$\hat{\beta_0}$ ， $\hat{\beta_1}$ = $arg\ min_{\beta_0 , \beta_1}$ ( $\sum_{i=1}^{n}(y_i-\hat{y_i})^2$ ) = $arg\ min_{\beta_0,\ \beta_1}(\sum_{i = 1}^{n}(y_i-\hat{\beta_0}-\hat{\beta_0}x_i)^2)$

$$
\hat{\beta_0},\hat{\beta_1}=arg\ min_{\beta_0,\beta_1}(\sum_{i = 1}^{n}(\hat{\mu_i})^2)
$$

我们称

$$
\hat{\mu_i}=y_i-\hat{\beta_0}-\hat{\beta_1}x_i
$$

为残差。

***多元线性回归***

顾名思义，就是用多个变量进行线性回归。

如果$\mu$和之前的$x$相关，那么我们就说具有内生性，进而对我们的回归结果产生巨大的影响。

我们可以通过下面的程序验证核心解释变量和我们的干扰项是否相关，从而判断回归的效果是否良好。

```matlab
%% 蒙特卡洛模拟：内生性会造成回归系数的巨大误差
times = 300;  % 蒙特卡洛的次数
R = zeros(times,1);  % 用来储存扰动项u和x1的相关系数
K = zeros(times,1);  % 用来储存遗漏了x2之后，只用y对x1回归得到的回归系数
for i = 1: times
    n = 30;  % 样本数据量为n
    x1 = -10+rand(n,1)*20;   % x1在-10和10上均匀分布，大小为30*1
    u1 = normrnd(0,5,n,1) - rand(n,1);  % 随机生成一组随机数
    x2 = 0.3*x1 + u1;   % x2与x1的相关性不确定， 因为我们设定了x2要加上u1这个随机数
    % 这里的系数0.3我随便给的，没特殊的意义，你也可以改成其他的测试。
    u = normrnd(0,1,n,1);  % 扰动项u服从标准正态分布
    y = 0.5 + 2 * x1 + 5 * x2 + u ;  % 构造y
    k = (n*sum(x1.*y)-sum(x1)*sum(y))/(n*sum(x1.*x1)-sum(x1)*sum(x1)); % y = k*x1+b 回归估计出来的k
    K(i) = k;
    u = 5 * x2 + u;  % 因为我们回归中忽略了5*x2，所以扰动项要加上5*x2
    r = corrcoef(x1,u);  % 2*2的相关系数矩阵
    R(i) = r(2,1);
end
plot(R,K,'*')
xlabel("x_1和u'的相关系数")
ylabel("k的估计值")
```

***虚拟变量的设置***

对于某一些不好量化的指标，我们可以将其这样设置。

比如性别，我们就令其Gender , 当男则为1，否则为0，之后再添加一个系数。如果是判断该个体和其他所有个体的某种对比时，我们可以设置变量A，当属于该个体时为1，否则设置为0，这样也可以区别出这些变量的特征。

***含有交互项的自变量***

将式子关于某个变量求偏导后，很容易会发现和另一个变量有关，我们需要在另一个变量的一些特殊位置进行分析，对于系数也不难进行校验。

多元线性回归代码参考

```matlab
beta = nlinfit(x, y, model, beta0);
% 其中x为多个自变量,y为一个因变量,model为我们假设的函数模型,beta0为系统的初值
% model设置的时候可以用beta(i)来代表第i个参数
% 举例为x = [x1, x2], beta0 = [a1, b1, c1, d1..], model = inline('beta(1)*x(:, 1) + beta(2)*x(:, 2)','beta', 'x');
```

之后对拟合出来的效果进行验证以及分析即可。

常见的线性回归包括：

***一元线性回归***

$$
\hat{y} = \hat{a} + \hat{b}x+u
$$

***双对数模型***

$$
ln\hat{y} = \hat{a}+\hat{b}lnx+u
$$

***半对数模型***

$$
\hat{y} = \hat{a}+\hat{b}lnx
$$

***半对数模型***

$$
ln\hat{y}=\hat{a}+\hat{b}x
$$

关于拟合效果的判定

1. 预测型回归看重$R^2$。
2. 解释型回归更多关注模型整体显著性以及自变量的统计显著性和经济意义显著性。

##### 1.2 0-1回归

模型：Logistic回归				Y的特点：二值变量(0-1)				例子：是否违约，是否得病

##### 1.3 定序回归

模型：probit定序回归			Y的特点：定序变量						例子：等级评定(优良差)

##### 1.4 计数回归

模型：泊松回归						Y的特点：计数变量						例子：每分钟的车流量

##### 1.5 生存回归

模型：Cox等比例风险回归	Y的特点：生存变量（截断数据）	例子：企业产品的寿命

#### 2.  方差分析

#### 3.  主成分分析

#####  （1）基本思想

##### 	是一种降维算法，将多个指标转化为少数几个主成分，这些主成分是原始变量的线性组合，且彼此之间互不相关，能反映出原始数据的大部分信息。

##### （2）主要步骤

1. 假设有$n$个样本，$p$个指标。可以构成大小为$n×p$ 的样本矩阵：


   $$
   x = \begin{bmatrix}   x_{11} & x_{12} & ... & x_{1p} \\   
   x_{21} & x_{22} & ... & x_{2p} \\ 
   ... & ... & ... & ... \\ 
   x_{n1} & x_{n2} & ... & x_{np} 
   \end{bmatrix}  =(x_1,x_2...x_p)
   $$
   
2. 对样本进行标准化操作

   按列计算均值和标准差。计算得到标准化数据。
   
   $$
   X_{ij} = \frac{x_{ij}-\overline{x_j}}{S_j}
   $$

   $$
   X = \begin{bmatrix}   X_{11} & X_{12} & ... & X_{1p} \\ 
   X_{21} & X_{22} & ... & X_{2p} \\
   ... & ... & ... & ... \\
   X_{n1} & X_{n2} & ... & X_{np} 
   \end{bmatrix}  =(X_1,X_2...X_p)
   $$

3. 计算协方差矩阵


   $$
   R = \begin{bmatrix}   r_{11} & r_{12} & ... & r_{1p} \\  
   r_{21} & r_{22} & ... & r_{2p} \\
   ... & ... & ... & ... \\ 
   R_{n1} & R_{n2} & ... & R_{np} 
   \end{bmatrix}  =(R_1,R_2...R_p)
   $$
   
   其中，对于每一项，表达式为：
   
   $$
   r_{ij}=\frac{1}{n - 1}\sum_{k=1}^{n} (X_{ki}-\overline{X_i})(X_{kj}-\overline{X_j})=\frac{1}{n-1}\sum_{k=1}^{n} X_{ki}X_{kj}
   $$
   
   该矩阵是半正定矩阵，且$tr(R)=\sum_{k=1}^{p} \lambda_k=p$。
   
4. 计算$R$的特征值和特征向量。

   特征值为$0 \le \lambda_p \le \lambda_{p-1} \le ... \le \lambda_1$

   特征向量为
   
   $$
   a_1 = \begin{bmatrix}   a_{11} \\ 
   a_{21} \\
   ... \\
   a_{p1}  
   \end{bmatrix} \ \ \ \ \ 
   a_2 = \begin{bmatrix}   a_{12} \\ 
   a_{22} \\
   ... \\
   a_{p2}  
   \end{bmatrix}  ,...,
   a_p = \begin{bmatrix} 
   a_{1p} \\ 
   a_{2p} \\ 
   ... \\
   a_{pp}  \end{bmatrix}
   $$

5. 计算主成分贡献率和累计贡献率
6. 
   $$
   贡献率=\frac{\lambda_i}{\sum_{k=1}^{p} \lambda_k}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ 累计贡献率=\frac{\sum_{k=1}^{i}\lambda_k}{\sum_{k=1}^{p}\lambda_k}\ \ (i = 1,2...p)
   $$

6. 写出主成分

   一般累计贡献率超过80%的特征值所对应的前$m$个主成分$(m\le p)$。第$i$个主成分：
   
   $$
   F_i=a_{1i}X_1+a_{2i}X_2+...+a_{pi}X_p \ \ \ \ \ \ \ \ (i=1,2...m)
   $$

7. 根据系数分析主成分里面的因素。

##### （3）利用主成分分析的一些优点及应用场景

1. 不可应用于评价类
2. 可用于聚类和回归分析。

##### （4）代码实现

```matlab
clear;clc
load data1.mat   % 主成分聚类
%  load data2.mat   % 主成分回归

% 注意，这里可以对数据先进行描述性统计
% 描述性统计的内容见第5讲.相关系数
[n,p] = size(x);  % n是样本个数，p是指标个数

%% 第一步：对数据x标准化为X
X=zscore(x);   % matlab内置的标准化函数（x-mean(x)）/std(x)

%% 第二步：计算样本协方差矩阵
R = cov(X);

%% 注意：以上两步可合并为下面一步：直接计算样本相关系数矩阵
R = corrcoef(x);
disp('样本相关系数矩阵为：')
disp(R)

%% 第三步：计算R的特征值和特征向量
% 注意：R是半正定矩阵，所以其特征值不为负数
% R同时是对称矩阵，Matlab计算对称矩阵时，会将特征值按照从小到大排列哦
% eig函数的详解见第一讲层次分析法的视频
[V,D] = eig(R);  % V 特征向量矩阵  D 特征值构成的对角矩阵


%% 第四步：计算主成分贡献率和累计贡献率
lambda = diag(D);  % diag函数用于得到一个矩阵的主对角线元素值(返回的是列向量)
lambda = lambda(end:-1:1);  % 因为lambda向量是从小大到排序的，我们将其调个头
contribution_rate = lambda / sum(lambda);  % 计算贡献率
cum_contribution_rate = cumsum(lambda)/ sum(lambda);   % 计算累计贡献率  cumsum是求累加值的函数
disp('特征值为：')
disp(lambda')  % 转置为行向量，方便展示
disp('贡献率为：')
disp(contribution_rate')
disp('累计贡献率为：')
disp(cum_contribution_rate')
disp('与特征值对应的特征向量矩阵为：')
% 注意：这里的特征向量要和特征值一一对应，之前特征值相当于颠倒过来了，因此特征向量的各列需要颠倒过来
%  rot90函数可以使一个矩阵逆时针旋转90度，然后再转置，就可以实现将矩阵的列颠倒的效果
V=rot90(V)';
disp(V)


%% 计算我们所需要的主成分的值
m =input('请输入需要保存的主成分的个数:  ');
F = zeros(n,m);  %初始化保存主成分的矩阵（每一列是一个主成分）
for i = 1:m
    ai = V(:,i)';   % 将第i个特征向量取出，并转置为行向量
    Ai = repmat(ai,n,1);   % 将这个行向量重复n次，构成一个n*p的矩阵
    F(:, i) = sum(Ai .* X, 2);  % 注意，对标准化的数据求了权重后要计算每一行的和
end

%% (1)主成分聚类 ： 将主成分指标所在的F矩阵复制到Excel表格，然后再用Spss进行聚类
% 在Excel第一行输入指标名称（F1,F2, ..., Fm）
% 双击Matlab工作区的F,进入变量编辑中，然后复制里面的数据到Excel表格
% 导出数据之后，我们后续的分析就可以在Spss中进行。

%%（2）主成分回归：将x使用主成分得到主成分指标，并将y标准化，接着导出到Excel，然后再使用Stata回归
% Y = zscore(y);  % 一定要将y进行标准化哦~
% 在Excel第一行输入指标名称（Y,F1, F2, ..., Fm）
% 分别双击Matlab工作区的Y和F,进入变量编辑中，然后复制里面的数据到Excel表格
% 导出数据之后，我们后续的分析就可以在Stata中进行。
```



#### 4.灰色关联分析

##### （1）基本思想

##### 	根据序列曲线的几何形状的相似程度来判断其联系是否紧密。曲线越接近，相应序列之间的关联度就越大，反之越小。

##### （2）其他方法相比于灰色预测的劣势：

1. 需要大量的数据，数据量少就难以找出统计规律。

2. 要求样本服从某个概率分布，要求各种因素数据与系统特征数据之间呈现线性关系且各因素间彼此无关，这都比较苛刻。
3. 计算量过大。
4. 量化和定性分析结果不相符，导致最终总结出来的规律遭到歪曲和颠倒。

##### （3）对与存在母序列的具体操作步骤

1. **画出统计图**，简单分析一下图像的性质。(没啥用)

2. **确定分析序列**。选准反映系统行为特征的序列，称为系统行为的映射量，用映射量间接表征系统行为。

   1. 母序列（参考序列、母指标）：反映系统行为特征的数据序列。


      $$
      X_0 = (X_0(1),X_0(2)...X_0(n))^{T}
      $$

   2. 子序列（比较序列、子指标）：影响系统的行为的因素组成的序列。


      $$
      X_1 = (X_1(1),X_1(2)...X_1(n))^{T}
      $$

      $$
      ...
      $$

      $$
      X_m = (X_m(1),X_m(2)...X_m(n))^{T}
      $$

3. **对变量进行预处理**(目的：去量纲、缩小变量范围简化计算)。

    1. 求出每个指标的均值。

    2. 每个元素除以均值得到结果。

4. **计算**子序列中各个指标与母序列的**关联系数**。

   ​	两极最小差为：
   
   $$
   a = min_i(min_k|X_0(k)-X_i(k)|)
   $$
   
   ​	两极最大差为：

$$
b = max_i(max_k|X_0(k)-X_i(k)|)
$$

5. 定义关联系数$\gamma$：


   $$
   \gamma\ (X_0(k),X_i(k)) = \frac{a + \rho b}{|X_0(k)-X_i(k)|+\rho b} \ \ \ \ \ \ \ \ \ \  \rho 是分辨系数，一般取0.5
   $$
   
   而对于两个指标$X_0$和$X_i$。只需要将序列中的每个取值进行相加求和并且取平均即可求出其灰色关联度。
   
   $$
   \gamma\ (X_0,X_i) = \frac{1}{n} \sum_{k = 1}^{n} \gamma\ (X_0(k),X_i(k))\ \ \ \ \ \ \ \ \
   $$

6. 比较几个灰色关联度，其中越大的表明其影响越大。

##### （4）存在母序列的代码实现

```matlab
load A.mat %处理的矩阵为A
Mean = mean(A);  % 求出每一列的均值以供后续的数据预处理
A = A ./ repmat(Mean,size(A,1),1);  %矩阵进行复制，复制为和A同等大小，然后使用点除（对应元素相除）
disp('预处理后的矩阵为：'); disp(A)
Y = A(:,1);  % 母序列
X = A(:,2:end); % 子序列
absX0_Xi = abs(X - repmat(Y,1,size(X,2)))  % 计算|X0-Xi|矩阵(在这里我们把X0定义为了Y)
a = min(min(absX0_Xi))    % 计算两级最小差a
b = max(max(absX0_Xi))  % 计算两级最大差b
rho = 0.5; % 分辨系数取0.5
gamma = (a+rho*b) ./ (absX0_Xi  + rho*b)  % 计算子序列中各个指标与母序列的关联系数
disp('子序列中各个指标的灰色关联度分别为：')
disp(mean(gamma))
```

##### （5）综合评价的操作步骤（不存在母序列的评价）

1. 对指标进行正向化。

2. 对正向化后的矩阵进行预处理得到矩阵$Z$。

3. 将预处理后的矩阵的每一行取出最大值构成母序列。

4. 计算各个指标与母序列的灰色关联度：$\gamma_1,\gamma_2....\gamma_m$。

5. 计算各个指标的权重：

   
   $$
   \omega_i = \frac{\gamma_i}{\gamma_1+\gamma_2+...+\gamma_m}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ i = 1....m
   $$

6. 第k个对象的得分为


   $$
   S_k = \sum_{i=1}^{m} Z_{ki}\omega_i
   $$

7. 对得分进行归一化，得到最终得分


   $$
   S'_i=\frac{S_i}{S_1+S_2+...S_n}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ i = 1....n
   $$

8. 根据最终得分求出结果

##### （6）不存在母序列的代码实现

```matlab
[n,m] = size(X);
disp(['共有' num2str(n) '个评价对象, ' num2str(m) '个评价指标']) 
Judge = input(['这' num2str(m) '个指标是否需要经过正向化处理，需要请输入1 ，不需要输入0：  ']);   %1
if Judge == 1
    Position = input('请输入需要正向化处理的指标所在的列，例如第2、3、6三列需要处理，那么你需要输入[2,3,6]： '); %[2,3,4]
    disp('请输入需要处理的这些列的指  标类型（1：极小型， 2：中间型， 3：区间型） ')
    Type = input('例如：第2列是极小型，第3列是区间型，第6列是中间型，就输入[1,3,2]：  '); %[2,1,3]
    % 注意，Position和Type是两个同维度的行向量
    for i = 1 : size(Position,2)  %这里需要对这些列分别处理，因此我们需要知道一共要处理的次数，即循环的次数
        X(:,Position(i)) = Positivization(X(:,Position(i)),Type(i),Position(i));
    % Positivization是我们自己定义的函数，其作用是进行正向化，其一共接收三个参数
    % 第一个参数是要正向化处理的那一列向量 X(:,Position(i))   回顾上一讲的知识，X(:,n)表示取第n列的全部元素
    % 第二个参数是对应的这一列的指标类型（1：极小型， 2：中间型， 3：区间型）
    % 第三个参数是告诉函数我们正在处理的是原始矩阵中的哪一列
    % 该函数有一个返回值，它返回正向化之后的指标，我们可以将其直接赋值给我们原始要处理的那一列向量
    end
    disp('正向化后的矩阵 X =  ')
    disp(X)
end
% =================================    （可选操作）正向化操作     ==============================================
%===========================================================================================================
%% 对正向化后的矩阵进行预处理
Mean = mean(X);  % 求出每一列的均值以供后续的数据预处理
Z = X ./ repmat(Mean,size(X,1),1);  
disp('预处理后的矩阵为：'); disp(Z)

%% 构造母序列和子序列
Y = max(Z,[],2);  % 母序列为虚拟的，用每一行的最大值构成的列向量表示母序列
X = Z; % 子序列就是预处理后的数据矩阵

%% 计算得分
absX0_Xi = abs(X - repmat(Y,1,size(X,2)))  % 计算|X0-Xi|矩阵
a = min(min(absX0_Xi))    % 计算两级最小差a
b = max(max(absX0_Xi))  % 计算两级最大差b
rho = 0.5; % 分辨系数取0.5
gamma = (a+rho*b) ./ (absX0_Xi  + rho*b)  % 计算子序列中各个指标与母序列的关联系数
weight = mean(gamma) / sum(mean(gamma));  % 利用子序列中各个指标的灰色关联度计算权重
score = sum(X .* repmat(weight,size(X,1),1),2);   % 未归一化的得分
stand_S = score / sum(score);   % 归一化后的得分
[sorted_S,index] = sort(stand_S ,'descend') % 进行排序


function [posit_x] = Positivization(x,type,i)
% 输入变量有三个：
% x：需要正向化处理的指标对应的原始列向量
% type： 指标的类型（1：极小型， 2：中间型， 3：区间型）
% i: 正在处理的是原始矩阵中的哪一列
% 输出变量posit_x表示：正向化后的列向量
    if type == 1  %极小型
        disp(['第' num2str(i) '列是极小型，正在正向化'] )
        posit_x = Min2Max(x);  %调用Min2Max函数来正向化
        disp(['第' num2str(i) '列极小型正向化处理完成'] )
        disp('~~~~~~~~~~~~~~~~~~~~分界线~~~~~~~~~~~~~~~~~~~~')
    elseif type == 2  %中间型
        disp(['第' num2str(i) '列是中间型'] )
        best = input('请输入最佳的那一个值： ');
        posit_x = Mid2Max(x,best);
        disp(['第' num2str(i) '列中间型正向化处理完成'] )
        disp('~~~~~~~~~~~~~~~~~~~~分界线~~~~~~~~~~~~~~~~~~~~')
    elseif type == 3  %区间型
        disp(['第' num2str(i) '列是区间型'] )
        a = input('请输入区间的下界： ');
        b = input('请输入区间的上界： '); 
        posit_x = Inter2Max(x,a,b);
        disp(['第' num2str(i) '列区间型正向化处理完成'] )
        disp('~~~~~~~~~~~~~~~~~~~~分界线~~~~~~~~~~~~~~~~~~~~')
    else
        disp('没有这种类型的指标，请检查Type向量中是否有除了1、2、3之外的其他值')
    end
end

function [posit_x] = Inter2Max(x,a,b)
    r_x = size(x,1);  % row of x 
    M = max([a-min(x),max(x)-b]);
    posit_x = zeros(r_x,1);   %zeros函数用法: zeros(3)  zeros(3,1)  ones(3)
    % 初始化posit_x全为0  初始化的目的是节省处理时间
    for i = 1: r_x
        if x(i) < a
           posit_x(i) = 1-(a-x(i))/M;
        elseif x(i) > b
           posit_x(i) = 1-(x(i)-b)/M;
        else
           posit_x(i) = 1;
        end
    end
end

function [posit_x] = Min2Max(x)
    posit_x = max(x) - x;
     %posit_x = 1 ./ x;    %如果x全部都大于0，也可以这样正向化
end

function [posit_x] = Mid2Max(x,best)
    M = max(abs(x-best));
    posit_x = 1 - abs(x-best) / M;
end
```

