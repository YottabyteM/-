# 粒子群算法

## 概念

### 什么是粒子群算法

​		粒子群算法通过设计一种无质量的粒子来模拟鸟群中的鸟，粒子仅具有两个属性：速度和位置，速度代表移动的快慢，位置代表移动的方向。每个粒子在搜索空间中单独的搜寻最优解，并将其记为当前个体极值，并将个体极值与整个粒子群里的其他粒子共享，找到最优的那个个体极值作为整个粒子群的当前全局最优解，粒子群中的所有粒子根据自己找到的当前个体极值和整个粒子群共享的当前全局最优解来调整自己的速度和位置。
<img src="C:\Users\戴廷钧\Desktop\img\AHP\C1.png" style="zoom:60%;" />

### 公式表示

<img src="C:\Users\戴廷钧\Desktop\img\AHP\C2.png" style="zoom:60%;" />
$$
第i只鸟第d步的速度=上一步自身的速度惯性+自我认知部分+社会认知部分 \\
$$

$$
v_{i}^{d}=\omega v_{i}^{d-1}+c_{1}r_{1}(pbest_{i}^{d}-x_{i}^{d})+c_{2}r_{2}(gbest^{d}-x_{i}^{d}) \\
$$

$$
r_{1}和r_{2}是[0,1]上的随机数
$$

$$
第i只鸟第d+1步所在的位置=第d步所在的位置+第d步的速度 \\
$$

$$
x_{i}^{d+1}=x_{i}^{d}+v_{i}^{d} \\ 
$$

$$
接下来的算法优化主要围绕学习因子c_{1}、c_{2}和惯性权重\omega 进行
$$

### 算法流程

<img src="C:\Users\戴廷钧\Desktop\img\AHP\C3.png" style="zoom:60%;" />

## 代码

```matlab
%% 粒子群算法中的预设参数
n = 10; % 粒子数量
narvs = 1; % 变量个数
c1 = 2;  % 每个粒子的个体学习因子，也称为个体加速常数
c2 = 2;  % 每个粒子的社会学习因子，也称为社会加速常数
w = 0.9;  % 惯性权重
K = 50;  % 迭代的次数
vmax = 1.2; % 粒子的最大速度
x_lb = -3; % x的下界
x_ub = 3; % x的上界

%% 求解函数y = 11*sin(x) + 7*cos(5*x)在[-3,3]内的最大值
%% Obj_fun1()函数用于计算上述函数值

%% 初始化粒子的位置和速度
x = zeros(n,narvs);
for i = 1: narvs
    x(:,i) = x_lb(i) + (x_ub(i)-x_lb(i))*rand(n,1);    % 随机初始化粒子所在的位置在定义域内
end
v = -vmax + 2*vmax .* rand(n,narvs);  % 随机初始化粒子的速度（这里我们设置为[-vmax,vmax]）


%% 计算适应度
fit = zeros(n,1);  % 初始化这n个粒子的适应度全为0
for i = 1:n  % 循环整个粒子群，计算每一个粒子的适应度
    fit(i) = Obj_fun1(x(i,:));   % 调用Obj_fun1函数来计算适应度（这里写成x(i,:)主要是为了和以后遇到的多元函数互通）
end
pbest = x;   % 初始化这n个粒子迄今为止找到的最佳位置（是一个n*narvs的向量）
ind = find(fit == max(fit), 1);  % 找到适应度最大的那个粒子的下标
gbest = x(ind,:);  % 定义所有粒子迄今为止找到的最佳位置（是一个1*narvs的向量）

%% 迭代K次来更新速度与位置
fitnessbest = ones(K,1);  % 初始化每次迭代得到的最佳的适应度
for d = 1:K  % 开始迭代，一共迭代K次
    for i = 1:n   % 依次更新第i个粒子的速度与位置
        v(i,:) = w*v(i,:) + c1*rand(1)*(pbest(i,:) - x(i,:)) + c2*rand(1)*(gbest - x(i,:));  % 更新第i个粒子的速度
        % 如果粒子的速度超过了最大速度限制，就对其进行调整
        for j = 1: narvs
            if v(i,j) < -vmax(j)
                v(i,j) = -vmax(j);
            elseif v(i,j) > vmax(j)
                v(i,j) = vmax(j);
            end
        end
        x(i,:) = x(i,:) + v(i,:); % 更新第i个粒子的位置
        % 如果粒子的位置超出了定义域，就对其进行调整
        for j = 1: narvs
            if x(i,j) < x_lb(j)
                x(i,j) = x_lb(j);
            elseif x(i,j) > x_ub(j)
                x(i,j) = x_ub(j);
            end
        end
        fit(i) = Obj_fun1(x(i,:));  % 重新计算第i个粒子的适应度
        if fit(i) > Obj_fun1(pbest(i,:))   % 如果第i个粒子的适应度大于这个粒子迄今为止找到的最佳位置对应的适应度
            pbest(i,:) = x(i,:);   % 那就更新第i个粒子迄今为止找到的最佳位置
        end
        if  fit(i) > Obj_fun1(gbest)  % 如果第i个粒子的适应度大于所有的粒子迄今为止找到的最佳位置对应的适应度
            gbest = pbest(i,:);   % 那就更新所有粒子迄今为止找到的最佳位置
        end
    end
    fitnessbest(d) = Obj_fun1(gbest);  % 更新第d次迭代得到的最佳的适应度
end
```

## 算法的改进

### 针对惯性权重

#### 自适应惯性权重

根据适应度(即函数的值)调整惯性权重的值

对于求解最小值问题：

适应度越小，说明距离最优解越近，此时更需要局部搜索

适应度越大，说明距离最优解越远，此时更需要全局搜索

#### 随机惯性权重

惯性权重值为随机值(一般在0.2~0.5之间)

### 针对学习因子

#### 压缩(收缩)因子法

#### 非对称学习因子

## Matlab自带的粒子群函数

